<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Audio Classification Project</title>
  <style>
    body {
      font-family: 'Arial', sans-serif;
      margin: 18px;
      line-height: 1.6;
      text-align: center;
      background-color: #f0f0f0; /* Background color for the entire page */
    }
    h1, h2, h3 {
      color: #ffb3c6;
    }
    p {
      color: white; /* Change the text color to white */
    }
    .center-box {
      margin-top: 50px; /* Adjust the margin as needed */
    }
    .color1 {
      color: #fb6f92;
    }
    .color2 {
      color: #ffb3c6;
    }
  </style>
</head>
<body>
  <div class="center-box">
    <h3><strong><span class="color1">Audio Classification</span> <span class="color2"> Project</span></strong></h3>
  </div>
  
  <p>The objective of this application is to perform audio classification to swiftly analyse audio files (.wav format) and provide a rapid classification of the sound into its respective class. The application utilizes the power of ANN’s i.e. Artificial Neural Networks to reliably predict the sound class with remarkable accuracy and precision.</p>

  <p>The dataset comprises 8732 labeled sound excerpts (4s each) from ten urban sound categories. These include air for audio prediction, car horns, children playing, dog barking, drilling, engine idling, gunshots, jackhammers, sirens, and street music. Before model development, we perform basic data preprocessing and feature extraction on audio signals. Each model is then evaluated based on accuracy, training time, and prediction time. Model deployment allows users to load a desired sound output for successful deployment, discussed in detail.</p>

  <h3>Usages</h3>
  <p>-	This project was programmed in Python language (ver. 3.11.5).</p>
  <p>-	Some of the libraries used in this project include TensorFlow, pickle, scikit-learn, librosa, Matplotlib, Seaborn, flask, etc.</p>
  <p>-	-	Web-Application created using Streamlit.</p>

  <h3>How to use it?</h3>
  <p>- Log into your account.</p>
  <p>- Go to the Model tab of the website and upload the audio file you wish to be analysed. You can drag and drop the file into the bin or click on the Browse Files button and click on the file you want to upload.</p>
  <p>- Note that the application can handle only “.wav” format files up to 200 MB’s.</p>
  <p>- Click on the Predict button which appears below the upload bin. The application shall then analyse and show its class prediction.</p>
  <p>- Also provided are additional tabs Info and Insights. Here, you can go through the source dataset the developers used to build the audio classifier and also view a dashboard which lets you see visualizations summarizing the overall characteristics of the dataset, for example: frequency, volume, etc.</p>
  <p>- You can click on the Contact Us tab wherein you may leave your valuable feedback or report issues with the page to the developers and administrators via email.</p>

  <h3>Objective and Goal of the Project:</h3>
  <p>We aim to develop a practical application using deep learning to assist deaf individuals in perceiving their surroundings. This software allows users to upload audio files, generating a detailed classification report. Our goal is to create a valuable tool for deaf individuals, enhancing their ability to comprehend the sounds around them and connect with the world.</p>

  <h3>Problem Statement:</h3>
  <p>With the successful deployment of the web application, our project addresses the fundamental goal of helping deaf individuals understand their environment through sound classification.</p>
</body>
</html>
